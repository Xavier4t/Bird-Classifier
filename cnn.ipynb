{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.utils import class_weight\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import keras.models\n",
    "from keras.layers import Input,Dense, Dropout, Activation, Flatten, Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features 'mel', 'mfcc' or 'freq_power'\n",
    "def selectFeatures(feature='mel'):\n",
    "    feat = os.path.join(\"bird_data\",\"features\")\n",
    "    train_folder = os.path.join(feat,f'{feature}_features', 'train')\n",
    "    test_folder = os.path.join(feat,f'{feature}_features', 'test')\n",
    "    val_folder = os.path.join(feat,f'{feature}_features', 'val')\n",
    "    return train_folder, test_folder, val_folder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder, test_folder, val_folder = selectFeatures('mel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and target size\n",
    "BATCH_SIZE = 16\n",
    "TARGET_SIZE = (720,288)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selectModel(BATCH_SIZE=32, TARGET_SIZE=(728,288)):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(720, 288, 3)))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 718, 286, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 716, 284, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 358, 142, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 358, 142, 64)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3253504)           0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                208224320 \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 208,244,362\n",
      "Trainable params: 208,244,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "selectModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, verbose=1)\n",
    "callbacks = [early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataGenerator(feed='TRAIN'):\n",
    "    if feed=='TRAIN':\n",
    "        return ImageDataGenerator(preprocessing_function=preprocess_input,  \n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.1,\n",
    "                                   fill_mode='nearest',\n",
    "                                   horizontal_flip = False)\n",
    "    elif feed=='TEST':\n",
    "        return ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "    else:\n",
    "        print('Wrong argument. Enter \"TRAIN\"  or \"TEST\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dg=dataGenerator()\n",
    "test_dg=dataGenerator('TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagenFlow(DATAGEN, FOLDER, TARGET_SIZE, BATCH_SIZE, SHUFFLE=True):\n",
    "    return DATAGEN.flow_from_directory(FOLDER, target_size = TARGET_SIZE, batch_size = BATCH_SIZE, class_mode = 'categorical', shuffle=SHUFFLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datagenFlow(train_dg, train_folder, TARGET_SIZE, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set= datagenFlow(test_dg, test_folder, TARGET_SIZE, BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set= datagenFlow(test_dg, val_folder, TARGET_SIZE, BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classWeights(tset):\n",
    "    class_weights = class_weight.compute_class_weight('balanced', np.unique(tset.classes), tset.classes)\n",
    "    weights = {label:w for label, w in zip(np.unique(training_set.classes), class_weights)}\n",
    "    return weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = classWeights(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_set, epochs=10, class_weight=weights,  validation_data = test_set, verbose=True, callbacks=callbacks, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Score(tset):\n",
    "    score = model.evaluate(tset, verbose=0)\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = Score(train_set)\n",
    "test_score = Score(test_set)\n",
    "val_score = Score(val_set)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_score, test_score, val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
